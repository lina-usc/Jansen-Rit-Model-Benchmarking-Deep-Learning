{
  "best_metric": 0.6454126238822937,
  "best_model_checkpoint": "./jr_transformer/checkpoint-25",
  "epoch": 48.0,
  "eval_steps": 500,
  "global_step": 1200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4,
      "grad_norm": 5616.5595703125,
      "learning_rate": 4.96e-05,
      "loss": 65035.875,
      "step": 10
    },
    {
      "epoch": 0.8,
      "grad_norm": 3169.950439453125,
      "learning_rate": 4.92e-05,
      "loss": 69393.1,
      "step": 20
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6454126238822937,
      "eval_runtime": 0.0625,
      "eval_samples_per_second": 1566.775,
      "eval_steps_per_second": 63.95,
      "step": 25
    },
    {
      "epoch": 1.2,
      "grad_norm": 1697.5455322265625,
      "learning_rate": 4.88e-05,
      "loss": 68105.5312,
      "step": 30
    },
    {
      "epoch": 1.6,
      "grad_norm": 1241.424072265625,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 65507.1375,
      "step": 40
    },
    {
      "epoch": 2.0,
      "grad_norm": 1200.004638671875,
      "learning_rate": 4.8e-05,
      "loss": 67538.6562,
      "step": 50
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.816422700881958,
      "eval_runtime": 0.0204,
      "eval_samples_per_second": 4803.237,
      "eval_steps_per_second": 196.05,
      "step": 50
    },
    {
      "epoch": 2.4,
      "grad_norm": 1148.718017578125,
      "learning_rate": 4.76e-05,
      "loss": 62133.5188,
      "step": 60
    },
    {
      "epoch": 2.8,
      "grad_norm": 1324.2767333984375,
      "learning_rate": 4.72e-05,
      "loss": 68585.1812,
      "step": 70
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8503506779670715,
      "eval_runtime": 0.0248,
      "eval_samples_per_second": 3946.708,
      "eval_steps_per_second": 161.09,
      "step": 75
    },
    {
      "epoch": 3.2,
      "grad_norm": 1334.7559814453125,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 72527.5813,
      "step": 80
    },
    {
      "epoch": 3.6,
      "grad_norm": 1155.7103271484375,
      "learning_rate": 4.64e-05,
      "loss": 66873.6313,
      "step": 90
    },
    {
      "epoch": 4.0,
      "grad_norm": 1456.7955322265625,
      "learning_rate": 4.600000000000001e-05,
      "loss": 66569.5125,
      "step": 100
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9061101675033569,
      "eval_runtime": 0.0183,
      "eval_samples_per_second": 5367.272,
      "eval_steps_per_second": 219.072,
      "step": 100
    },
    {
      "epoch": 4.4,
      "grad_norm": 1207.7352294921875,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 62296.8875,
      "step": 110
    },
    {
      "epoch": 4.8,
      "grad_norm": 1225.9066162109375,
      "learning_rate": 4.52e-05,
      "loss": 67792.225,
      "step": 120
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.9336374998092651,
      "eval_runtime": 0.0216,
      "eval_samples_per_second": 4546.721,
      "eval_steps_per_second": 185.58,
      "step": 125
    },
    {
      "epoch": 5.2,
      "grad_norm": 1309.392333984375,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 72479.1625,
      "step": 130
    },
    {
      "epoch": 5.6,
      "grad_norm": 1266.7603759765625,
      "learning_rate": 4.44e-05,
      "loss": 65163.1188,
      "step": 140
    },
    {
      "epoch": 6.0,
      "grad_norm": 1290.593505859375,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 67435.9187,
      "step": 150
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.9751635789871216,
      "eval_runtime": 0.0206,
      "eval_samples_per_second": 4761.01,
      "eval_steps_per_second": 194.327,
      "step": 150
    },
    {
      "epoch": 6.4,
      "grad_norm": 1286.166748046875,
      "learning_rate": 4.36e-05,
      "loss": 66283.7,
      "step": 160
    },
    {
      "epoch": 6.8,
      "grad_norm": 1153.6397705078125,
      "learning_rate": 4.32e-05,
      "loss": 68609.825,
      "step": 170
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.0174041986465454,
      "eval_runtime": 0.0199,
      "eval_samples_per_second": 4918.18,
      "eval_steps_per_second": 200.742,
      "step": 175
    },
    {
      "epoch": 7.2,
      "grad_norm": 1507.572021484375,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 66438.7188,
      "step": 180
    },
    {
      "epoch": 7.6,
      "grad_norm": 1244.103515625,
      "learning_rate": 4.24e-05,
      "loss": 66321.7375,
      "step": 190
    },
    {
      "epoch": 8.0,
      "grad_norm": 1310.2635498046875,
      "learning_rate": 4.2e-05,
      "loss": 66658.3562,
      "step": 200
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.0330082178115845,
      "eval_runtime": 0.021,
      "eval_samples_per_second": 4673.957,
      "eval_steps_per_second": 190.774,
      "step": 200
    },
    {
      "epoch": 8.4,
      "grad_norm": 1198.5916748046875,
      "learning_rate": 4.16e-05,
      "loss": 67384.65,
      "step": 210
    },
    {
      "epoch": 8.8,
      "grad_norm": 1340.7681884765625,
      "learning_rate": 4.12e-05,
      "loss": 65173.0938,
      "step": 220
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.058823823928833,
      "eval_runtime": 0.0212,
      "eval_samples_per_second": 4622.03,
      "eval_steps_per_second": 188.654,
      "step": 225
    },
    {
      "epoch": 9.2,
      "grad_norm": 1474.7469482421875,
      "learning_rate": 4.08e-05,
      "loss": 71256.1875,
      "step": 230
    },
    {
      "epoch": 9.6,
      "grad_norm": 1175.620849609375,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 67566.7188,
      "step": 240
    },
    {
      "epoch": 10.0,
      "grad_norm": 1390.1622314453125,
      "learning_rate": 4e-05,
      "loss": 63741.8625,
      "step": 250
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.1043246984481812,
      "eval_runtime": 0.0295,
      "eval_samples_per_second": 3322.49,
      "eval_steps_per_second": 135.612,
      "step": 250
    },
    {
      "epoch": 10.4,
      "grad_norm": 1151.25,
      "learning_rate": 3.960000000000001e-05,
      "loss": 64403.3313,
      "step": 260
    },
    {
      "epoch": 10.8,
      "grad_norm": 1480.434814453125,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 71282.425,
      "step": 270
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.1293773651123047,
      "eval_runtime": 0.0293,
      "eval_samples_per_second": 3346.783,
      "eval_steps_per_second": 136.603,
      "step": 275
    },
    {
      "epoch": 11.2,
      "grad_norm": 1220.94580078125,
      "learning_rate": 3.88e-05,
      "loss": 60197.7063,
      "step": 280
    },
    {
      "epoch": 11.6,
      "grad_norm": 1401.88623046875,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 70363.4375,
      "step": 290
    },
    {
      "epoch": 12.0,
      "grad_norm": 1406.404296875,
      "learning_rate": 3.8e-05,
      "loss": 68585.75,
      "step": 300
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.1493757963180542,
      "eval_runtime": 0.0186,
      "eval_samples_per_second": 5263.423,
      "eval_steps_per_second": 214.834,
      "step": 300
    },
    {
      "epoch": 12.4,
      "grad_norm": 1272.008056640625,
      "learning_rate": 3.76e-05,
      "loss": 69116.6938,
      "step": 310
    },
    {
      "epoch": 12.8,
      "grad_norm": 1217.8450927734375,
      "learning_rate": 3.72e-05,
      "loss": 63869.0375,
      "step": 320
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.1802860498428345,
      "eval_runtime": 0.0273,
      "eval_samples_per_second": 3594.877,
      "eval_steps_per_second": 146.73,
      "step": 325
    },
    {
      "epoch": 13.2,
      "grad_norm": 1281.3165283203125,
      "learning_rate": 3.68e-05,
      "loss": 69289.2188,
      "step": 330
    },
    {
      "epoch": 13.6,
      "grad_norm": 1430.60693359375,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 65577.575,
      "step": 340
    },
    {
      "epoch": 14.0,
      "grad_norm": 1258.6715087890625,
      "learning_rate": 3.6e-05,
      "loss": 65576.4,
      "step": 350
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.2104768753051758,
      "eval_runtime": 0.0204,
      "eval_samples_per_second": 4796.847,
      "eval_steps_per_second": 195.79,
      "step": 350
    },
    {
      "epoch": 14.4,
      "grad_norm": 1357.9901123046875,
      "learning_rate": 3.56e-05,
      "loss": 69886.1062,
      "step": 360
    },
    {
      "epoch": 14.8,
      "grad_norm": 1195.9901123046875,
      "learning_rate": 3.52e-05,
      "loss": 66068.95,
      "step": 370
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.240731120109558,
      "eval_runtime": 0.0261,
      "eval_samples_per_second": 3756.07,
      "eval_steps_per_second": 153.309,
      "step": 375
    },
    {
      "epoch": 15.2,
      "grad_norm": 1279.5809326171875,
      "learning_rate": 3.48e-05,
      "loss": 61231.0062,
      "step": 380
    },
    {
      "epoch": 15.6,
      "grad_norm": 1265.827880859375,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 65766.7188,
      "step": 390
    },
    {
      "epoch": 16.0,
      "grad_norm": 1378.7708740234375,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 71358.7375,
      "step": 400
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.252736210823059,
      "eval_runtime": 0.0185,
      "eval_samples_per_second": 5292.088,
      "eval_steps_per_second": 216.004,
      "step": 400
    },
    {
      "epoch": 16.4,
      "grad_norm": 1376.781982421875,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 67975.525,
      "step": 410
    },
    {
      "epoch": 16.8,
      "grad_norm": 1334.7510986328125,
      "learning_rate": 3.32e-05,
      "loss": 64479.825,
      "step": 420
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.2826824188232422,
      "eval_runtime": 0.023,
      "eval_samples_per_second": 4257.868,
      "eval_steps_per_second": 173.791,
      "step": 425
    },
    {
      "epoch": 17.2,
      "grad_norm": 1238.266845703125,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 67725.25,
      "step": 430
    },
    {
      "epoch": 17.6,
      "grad_norm": 1337.246337890625,
      "learning_rate": 3.24e-05,
      "loss": 68469.175,
      "step": 440
    },
    {
      "epoch": 18.0,
      "grad_norm": 1307.890625,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 65331.45,
      "step": 450
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.3022487163543701,
      "eval_runtime": 0.0187,
      "eval_samples_per_second": 5235.334,
      "eval_steps_per_second": 213.687,
      "step": 450
    },
    {
      "epoch": 18.4,
      "grad_norm": 1281.927001953125,
      "learning_rate": 3.16e-05,
      "loss": 68254.8125,
      "step": 460
    },
    {
      "epoch": 18.8,
      "grad_norm": 1310.5775146484375,
      "learning_rate": 3.12e-05,
      "loss": 64943.4375,
      "step": 470
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.3326624631881714,
      "eval_runtime": 0.0207,
      "eval_samples_per_second": 4741.185,
      "eval_steps_per_second": 193.518,
      "step": 475
    },
    {
      "epoch": 19.2,
      "grad_norm": 1479.455810546875,
      "learning_rate": 3.08e-05,
      "loss": 72228.1812,
      "step": 480
    },
    {
      "epoch": 19.6,
      "grad_norm": 1415.0059814453125,
      "learning_rate": 3.04e-05,
      "loss": 62809.7438,
      "step": 490
    },
    {
      "epoch": 20.0,
      "grad_norm": 1423.290283203125,
      "learning_rate": 3e-05,
      "loss": 66220.5688,
      "step": 500
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.3473817110061646,
      "eval_runtime": 0.031,
      "eval_samples_per_second": 3164.245,
      "eval_steps_per_second": 129.153,
      "step": 500
    },
    {
      "epoch": 20.4,
      "grad_norm": 1227.68408203125,
      "learning_rate": 2.96e-05,
      "loss": 69347.0437,
      "step": 510
    },
    {
      "epoch": 20.8,
      "grad_norm": 1295.203125,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 65761.0,
      "step": 520
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.3738540410995483,
      "eval_runtime": 0.0211,
      "eval_samples_per_second": 4652.899,
      "eval_steps_per_second": 189.914,
      "step": 525
    },
    {
      "epoch": 21.2,
      "grad_norm": 1395.1480712890625,
      "learning_rate": 2.88e-05,
      "loss": 63056.4625,
      "step": 530
    },
    {
      "epoch": 21.6,
      "grad_norm": 1434.5399169921875,
      "learning_rate": 2.84e-05,
      "loss": 69022.8,
      "step": 540
    },
    {
      "epoch": 22.0,
      "grad_norm": 1405.7626953125,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 65388.9187,
      "step": 550
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.4035831689834595,
      "eval_runtime": 0.0242,
      "eval_samples_per_second": 4045.249,
      "eval_steps_per_second": 165.112,
      "step": 550
    },
    {
      "epoch": 22.4,
      "grad_norm": 1401.5745849609375,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 67882.0188,
      "step": 560
    },
    {
      "epoch": 22.8,
      "grad_norm": 1300.964599609375,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 64666.3063,
      "step": 570
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.412283182144165,
      "eval_runtime": 0.0251,
      "eval_samples_per_second": 3901.715,
      "eval_steps_per_second": 159.254,
      "step": 575
    },
    {
      "epoch": 23.2,
      "grad_norm": 1577.4395751953125,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 68476.9,
      "step": 580
    },
    {
      "epoch": 23.6,
      "grad_norm": 1424.917724609375,
      "learning_rate": 2.64e-05,
      "loss": 67477.625,
      "step": 590
    },
    {
      "epoch": 24.0,
      "grad_norm": 1393.7652587890625,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 65334.225,
      "step": 600
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.437013864517212,
      "eval_runtime": 0.0222,
      "eval_samples_per_second": 4416.575,
      "eval_steps_per_second": 180.268,
      "step": 600
    },
    {
      "epoch": 24.4,
      "grad_norm": 1329.309814453125,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 69437.025,
      "step": 610
    },
    {
      "epoch": 24.8,
      "grad_norm": 1360.089599609375,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 63862.0813,
      "step": 620
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.4498391151428223,
      "eval_runtime": 0.0245,
      "eval_samples_per_second": 3994.459,
      "eval_steps_per_second": 163.039,
      "step": 625
    },
    {
      "epoch": 25.2,
      "grad_norm": 1146.76513671875,
      "learning_rate": 2.48e-05,
      "loss": 67123.3,
      "step": 630
    },
    {
      "epoch": 25.6,
      "grad_norm": 1469.62939453125,
      "learning_rate": 2.44e-05,
      "loss": 68422.2312,
      "step": 640
    },
    {
      "epoch": 26.0,
      "grad_norm": 1047.4312744140625,
      "learning_rate": 2.4e-05,
      "loss": 63597.1937,
      "step": 650
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.4735051393508911,
      "eval_runtime": 0.0199,
      "eval_samples_per_second": 4925.37,
      "eval_steps_per_second": 201.035,
      "step": 650
    },
    {
      "epoch": 26.4,
      "grad_norm": 1261.395263671875,
      "learning_rate": 2.36e-05,
      "loss": 64722.7063,
      "step": 660
    },
    {
      "epoch": 26.8,
      "grad_norm": 1250.650146484375,
      "learning_rate": 2.32e-05,
      "loss": 69252.875,
      "step": 670
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.488538146018982,
      "eval_runtime": 0.0266,
      "eval_samples_per_second": 3681.455,
      "eval_steps_per_second": 150.263,
      "step": 675
    },
    {
      "epoch": 27.2,
      "grad_norm": 1370.83349609375,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 67197.3,
      "step": 680
    },
    {
      "epoch": 27.6,
      "grad_norm": 1282.74951171875,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 69143.3687,
      "step": 690
    },
    {
      "epoch": 28.0,
      "grad_norm": 1179.37841796875,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 62885.475,
      "step": 700
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.5061752796173096,
      "eval_runtime": 0.0197,
      "eval_samples_per_second": 4977.86,
      "eval_steps_per_second": 203.178,
      "step": 700
    },
    {
      "epoch": 28.4,
      "grad_norm": 1408.2998046875,
      "learning_rate": 2.16e-05,
      "loss": 63596.575,
      "step": 710
    },
    {
      "epoch": 28.8,
      "grad_norm": 1258.9700927734375,
      "learning_rate": 2.12e-05,
      "loss": 64110.2875,
      "step": 720
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.5170038938522339,
      "eval_runtime": 0.0221,
      "eval_samples_per_second": 4438.225,
      "eval_steps_per_second": 181.152,
      "step": 725
    },
    {
      "epoch": 29.2,
      "grad_norm": 1383.4501953125,
      "learning_rate": 2.08e-05,
      "loss": 74504.1313,
      "step": 730
    },
    {
      "epoch": 29.6,
      "grad_norm": 1228.5771484375,
      "learning_rate": 2.04e-05,
      "loss": 64624.7063,
      "step": 740
    },
    {
      "epoch": 30.0,
      "grad_norm": 1354.700439453125,
      "learning_rate": 2e-05,
      "loss": 67589.0625,
      "step": 750
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.5279723405838013,
      "eval_runtime": 0.0196,
      "eval_samples_per_second": 5005.624,
      "eval_steps_per_second": 204.311,
      "step": 750
    },
    {
      "epoch": 30.4,
      "grad_norm": 1239.7882080078125,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 64686.6312,
      "step": 760
    },
    {
      "epoch": 30.8,
      "grad_norm": 1545.3660888671875,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 72275.425,
      "step": 770
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.5470993518829346,
      "eval_runtime": 0.0211,
      "eval_samples_per_second": 4634.904,
      "eval_steps_per_second": 189.18,
      "step": 775
    },
    {
      "epoch": 31.2,
      "grad_norm": 1260.077880859375,
      "learning_rate": 1.88e-05,
      "loss": 62114.2,
      "step": 780
    },
    {
      "epoch": 31.6,
      "grad_norm": 1222.50732421875,
      "learning_rate": 1.84e-05,
      "loss": 67430.3,
      "step": 790
    },
    {
      "epoch": 32.0,
      "grad_norm": 1293.9775390625,
      "learning_rate": 1.8e-05,
      "loss": 67081.3562,
      "step": 800
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.5607163906097412,
      "eval_runtime": 0.0271,
      "eval_samples_per_second": 3615.302,
      "eval_steps_per_second": 147.563,
      "step": 800
    },
    {
      "epoch": 32.4,
      "grad_norm": 1380.6441650390625,
      "learning_rate": 1.76e-05,
      "loss": 64814.6375,
      "step": 810
    },
    {
      "epoch": 32.8,
      "grad_norm": 1455.62255859375,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 71152.6,
      "step": 820
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.571659803390503,
      "eval_runtime": 0.0213,
      "eval_samples_per_second": 4602.056,
      "eval_steps_per_second": 187.839,
      "step": 825
    },
    {
      "epoch": 33.2,
      "grad_norm": 1377.551513671875,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 64580.1937,
      "step": 830
    },
    {
      "epoch": 33.6,
      "grad_norm": 1447.7655029296875,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 64024.1375,
      "step": 840
    },
    {
      "epoch": 34.0,
      "grad_norm": 1574.7252197265625,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 69514.4312,
      "step": 850
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.580578088760376,
      "eval_runtime": 0.0269,
      "eval_samples_per_second": 3641.244,
      "eval_steps_per_second": 148.622,
      "step": 850
    },
    {
      "epoch": 34.4,
      "grad_norm": 1451.7655029296875,
      "learning_rate": 1.56e-05,
      "loss": 69766.1375,
      "step": 860
    },
    {
      "epoch": 34.8,
      "grad_norm": 1341.936767578125,
      "learning_rate": 1.52e-05,
      "loss": 62233.6188,
      "step": 870
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.5952422618865967,
      "eval_runtime": 0.024,
      "eval_samples_per_second": 4090.986,
      "eval_steps_per_second": 166.979,
      "step": 875
    },
    {
      "epoch": 35.2,
      "grad_norm": 1512.986328125,
      "learning_rate": 1.48e-05,
      "loss": 65861.7063,
      "step": 880
    },
    {
      "epoch": 35.6,
      "grad_norm": 1251.7313232421875,
      "learning_rate": 1.44e-05,
      "loss": 67877.3125,
      "step": 890
    },
    {
      "epoch": 36.0,
      "grad_norm": 1243.8216552734375,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 67222.1625,
      "step": 900
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.6029906272888184,
      "eval_runtime": 0.0238,
      "eval_samples_per_second": 4109.719,
      "eval_steps_per_second": 167.744,
      "step": 900
    },
    {
      "epoch": 36.4,
      "grad_norm": 1569.390869140625,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 68258.9375,
      "step": 910
    },
    {
      "epoch": 36.8,
      "grad_norm": 1285.02978515625,
      "learning_rate": 1.32e-05,
      "loss": 64251.7812,
      "step": 920
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.6147630214691162,
      "eval_runtime": 0.0198,
      "eval_samples_per_second": 4960.08,
      "eval_steps_per_second": 202.452,
      "step": 925
    },
    {
      "epoch": 37.2,
      "grad_norm": 1247.576904296875,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 63157.5125,
      "step": 930
    },
    {
      "epoch": 37.6,
      "grad_norm": 1443.9683837890625,
      "learning_rate": 1.24e-05,
      "loss": 69295.9062,
      "step": 940
    },
    {
      "epoch": 38.0,
      "grad_norm": 1305.97607421875,
      "learning_rate": 1.2e-05,
      "loss": 67139.8687,
      "step": 950
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.6227247714996338,
      "eval_runtime": 0.0321,
      "eval_samples_per_second": 3048.48,
      "eval_steps_per_second": 124.428,
      "step": 950
    },
    {
      "epoch": 38.4,
      "grad_norm": 1201.2066650390625,
      "learning_rate": 1.16e-05,
      "loss": 65564.6938,
      "step": 960
    },
    {
      "epoch": 38.8,
      "grad_norm": 1370.4488525390625,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 68711.1,
      "step": 970
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.631787657737732,
      "eval_runtime": 0.0193,
      "eval_samples_per_second": 5081.428,
      "eval_steps_per_second": 207.405,
      "step": 975
    },
    {
      "epoch": 39.2,
      "grad_norm": 1400.9664306640625,
      "learning_rate": 1.08e-05,
      "loss": 66292.0437,
      "step": 980
    },
    {
      "epoch": 39.6,
      "grad_norm": 1396.8018798828125,
      "learning_rate": 1.04e-05,
      "loss": 65320.3187,
      "step": 990
    },
    {
      "epoch": 40.0,
      "grad_norm": 1290.61376953125,
      "learning_rate": 1e-05,
      "loss": 66909.375,
      "step": 1000
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.6393471956253052,
      "eval_runtime": 0.0249,
      "eval_samples_per_second": 3941.599,
      "eval_steps_per_second": 160.882,
      "step": 1000
    },
    {
      "epoch": 40.4,
      "grad_norm": 1150.35205078125,
      "learning_rate": 9.600000000000001e-06,
      "loss": 64991.8562,
      "step": 1010
    },
    {
      "epoch": 40.8,
      "grad_norm": 1210.5633544921875,
      "learning_rate": 9.2e-06,
      "loss": 66396.45,
      "step": 1020
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.6453349590301514,
      "eval_runtime": 0.0212,
      "eval_samples_per_second": 4615.439,
      "eval_steps_per_second": 188.385,
      "step": 1025
    },
    {
      "epoch": 41.2,
      "grad_norm": 1230.99365234375,
      "learning_rate": 8.8e-06,
      "loss": 65424.9812,
      "step": 1030
    },
    {
      "epoch": 41.6,
      "grad_norm": 1481.52392578125,
      "learning_rate": 8.400000000000001e-06,
      "loss": 67164.7688,
      "step": 1040
    },
    {
      "epoch": 42.0,
      "grad_norm": 1283.499267578125,
      "learning_rate": 8.000000000000001e-06,
      "loss": 69262.3375,
      "step": 1050
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.6496851444244385,
      "eval_runtime": 0.0213,
      "eval_samples_per_second": 4610.056,
      "eval_steps_per_second": 188.166,
      "step": 1050
    },
    {
      "epoch": 42.4,
      "grad_norm": 1328.3511962890625,
      "learning_rate": 7.6e-06,
      "loss": 66984.1875,
      "step": 1060
    },
    {
      "epoch": 42.8,
      "grad_norm": 1381.5989990234375,
      "learning_rate": 7.2e-06,
      "loss": 63520.7,
      "step": 1070
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.6576859951019287,
      "eval_runtime": 0.028,
      "eval_samples_per_second": 3498.496,
      "eval_steps_per_second": 142.796,
      "step": 1075
    },
    {
      "epoch": 43.2,
      "grad_norm": 1450.5814208984375,
      "learning_rate": 6.800000000000001e-06,
      "loss": 70364.6687,
      "step": 1080
    },
    {
      "epoch": 43.6,
      "grad_norm": 1219.0887451171875,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 64653.2438,
      "step": 1090
    },
    {
      "epoch": 44.0,
      "grad_norm": 1203.0084228515625,
      "learning_rate": 6e-06,
      "loss": 67400.725,
      "step": 1100
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.6612690687179565,
      "eval_runtime": 0.0331,
      "eval_samples_per_second": 2962.079,
      "eval_steps_per_second": 120.901,
      "step": 1100
    },
    {
      "epoch": 44.4,
      "grad_norm": 1545.7537841796875,
      "learning_rate": 5.600000000000001e-06,
      "loss": 68548.7688,
      "step": 1110
    },
    {
      "epoch": 44.8,
      "grad_norm": 1224.584716796875,
      "learning_rate": 5.2e-06,
      "loss": 66203.3625,
      "step": 1120
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.6644326448440552,
      "eval_runtime": 0.0277,
      "eval_samples_per_second": 3537.791,
      "eval_steps_per_second": 144.4,
      "step": 1125
    },
    {
      "epoch": 45.2,
      "grad_norm": 1199.0831298828125,
      "learning_rate": 4.800000000000001e-06,
      "loss": 62907.1,
      "step": 1130
    },
    {
      "epoch": 45.6,
      "grad_norm": 1341.8211669921875,
      "learning_rate": 4.4e-06,
      "loss": 67845.5875,
      "step": 1140
    },
    {
      "epoch": 46.0,
      "grad_norm": 1612.6298828125,
      "learning_rate": 4.000000000000001e-06,
      "loss": 67537.0188,
      "step": 1150
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.668325424194336,
      "eval_runtime": 0.0224,
      "eval_samples_per_second": 4372.227,
      "eval_steps_per_second": 178.458,
      "step": 1150
    },
    {
      "epoch": 46.4,
      "grad_norm": 1408.4620361328125,
      "learning_rate": 3.6e-06,
      "loss": 67477.4438,
      "step": 1160
    },
    {
      "epoch": 46.8,
      "grad_norm": 1326.6046142578125,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 65823.8687,
      "step": 1170
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.6705130338668823,
      "eval_runtime": 0.0244,
      "eval_samples_per_second": 4021.345,
      "eval_steps_per_second": 164.137,
      "step": 1175
    },
    {
      "epoch": 47.2,
      "grad_norm": 1320.7193603515625,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 70556.0875,
      "step": 1180
    },
    {
      "epoch": 47.6,
      "grad_norm": 1314.0247802734375,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 65834.4812,
      "step": 1190
    },
    {
      "epoch": 48.0,
      "grad_norm": 1219.840576171875,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 62844.75,
      "step": 1200
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.6720218658447266,
      "eval_runtime": 0.0323,
      "eval_samples_per_second": 3029.383,
      "eval_steps_per_second": 123.648,
      "step": 1200
    }
  ],
  "logging_steps": 10,
  "max_steps": 1250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
